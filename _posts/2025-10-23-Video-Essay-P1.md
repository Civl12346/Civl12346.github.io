---
layout: post
title: "Video-Essay Essay P1: A Philisophical Discussion of Arguments WIP"
---

### Introduction

### A Generalized Framework for Modelling Arguments
I think most people would agree that the basic purpose of an essay is to intelligently come to a conclusion about something (this can be coming to a conclusion yourself or guiding others towards a conclusion). This is most clearly seen in an opinion essay where ultimately some opinion is stated and then justified through the essay. Without this justification there would only be an opinion and no essay. Or, more simply, there is no argument being made. I think this is obvious to most people. When someone is arguing something it is generally considered to be common sense to provide reasons and justifications for how they came to the conclusion they are arguing for and why it is a correct conclusion to come to. I bring all this up because I think it is a good starting point for defining what an argument is and what it allows us to communicate.

If a stranger came to you and told you a fact they knew or an opinion they held would you take the fact as truth? Would you change your opinion to match theirs? I think most people, from a logical perspective, would not. This is because when someone asserts a statement, or a conclusion they have come to, it tells you something about them, but it does not tell you anything about their statement or the conclusion they have come to. There is not enough information for you to genuinely to come to any conclusion about what they said or a conclusion about yourself.

_I say, "I like frogs."_

_You reply, "So what?"_

You see, I have told you something of myself (that I like frogs), but I have told you nothing about frogs or your relationship to them. Similarly, if I say, _"frogs are green"_ I still have not told you something about frogs or your relationship to them. I have only told what I _think_. Can you trust that what I said about frogs is true? Do I mean all frogs are green or only one type of frog? If you thought frogs were blue, why would me saying otherwise lead you to think differently? This is because I have only said something about myself. Therefore, in order to speak about something other than ourselves, we must have more than just a conclusion.

> To develop out framework, we will call this kind of conclusion a **claim** (or **non-base claim**) which we'll define to mean a statement.

So, if a claim lets us only speak of ourselves, how do we speak about other things? I argue that this is where we need reasoning and something called a _base claim_.

> A **base claim** is a claim that acts as a reference for another claim.
>
> **Reason** is the relationship between a claim and a base claim.

> A **unit argument** (I'll explain the use of unit later) is a claim related to a base claim by the reason that connects them.

To try and illustrate why we've come up with these definitions, let's go back to _"frogs are green"_. How can we argue this? Well, we need a base claim. Let's say that I saw a frog, so our base claim is: _I saw a frog_. Then we have our initial claim: _frogs are green_. Then we need some reason (or relationship) to connect them. Maybe: _the frog I saw was green_. Therfore, my (unit) argument becomes: 

**I saw a frog. It is green. All frogs are green.**

There are two key things to note about this argument:
1. We have to make some implicit assumptions about our base claim for our argument to mean anything.

2. This is a bad argument.

Let's define some rules and new definitions for our framework and come back to these notes. Firstly, claims are only as good as the amount of acceptance we are willing to have in them (hence why most people would disagree with the statement: _all frogs are green_). If we accept a claim, then that claim is _true_. If we do not accept a claim, then that claim is _false_. Therefore, 

> **Truth** is a measure of acceptance.

We can then define claims based on their truth:

> An **accepted claim** is a claim which is considered to be true.
>
> An **unaccepted claim** is a claim which is considered to be false.
>
> An **uncertain claim** is a claim which is considered to be equally as likely to be true as it is to be false.
>
> A **sourced claim** is a claim which is considered to be true based on someone else's argument.

When looking at an argument, we see that you can provide multiple reasons to help justify your argument. In an essay, you might have one overarching conclusion with multiple supporting conclusions. This is highlighted by the Five-Paragraph Essay. Similarly, you can come to multiple conclusions from a singular supporting conclusion. To replicate this, we will say:

> A single claim can be connected to multiple base claims.
>
>A single base claim can be connected to multiple claims.

Intuitively, if I come to a conclusion about something using false information, then my conclusion must be false*. Similarly, if I come to a conclusion about someting using true information, then my conlusion must be true**. So,

> Assuming the reasoning is valid, a claim is only as true as the base claim it is reasoned from. Similarly, assuming the reasoning is valid, a claim reasoned from 
> multiple base claims is only as true as the average truth of the base claims.

 * * *
*You could accidentally come to a conclusion that is technically true but that would mean that the reasons used to reach that conclusion are likely not valid.

**Obviously you could come to a wrong conclusion but that would mean that the reasons used to reach that conclusion are likely not valid.
* * *

> A **valid reason** is a relationship that actually exits between a claim and base claim.

One more rule and then we'll try and put them into practice and see how this framework...well...works.

> The more **similar** a claim is to a base claim the **more valid** the reasoning between them tends to be.
>
> The more **different** a claim is from a base claim the **less valid** the reasoning between them tends to be.

Here is a quick example about truth within our frame work:

Let's say _a_ + _b_ + _c_ = _d_ 

where,

* _a_, _b_, and _c_ are our base claims. 
* _d_ is our non-base claim. 
* The addition and equality is how we reason _d_ from _a_, _b_, and _c_ (it is the relationship between them).

Now let's assume that

* _a_ = 5 is true (a statement we accept).
* _b_ = 3 is false (a statement we do not accept).
* _c_ = 4 is as equally likely to be true as it is to be false (a statemtent we are uncertain about).

Therfore, we claim that _d_ = 12. However, based on one of our previous rules, we see that our claim is **uncertain**.

> * * *
> Assuming the reasoning is valid, a claim reasoned from multiple base claims is only as true as the average truth of the base claims.
> * * *
> Let's say,
> * True = 1
> * Uncertain = 0
> * False = -1
>
> Then,
>
> (1 + 0 + -1) / 3 = **0**

We see that unless we are certain that our base claims are true we cannot be certain that the claims reasoned from them are also true.

Now let's go back to our previous argument and address our notes.

**I saw a frog. It is green. All frogs are green.**

I think it is safe to say **I saw a frog** is true. Most people would be willing to agree that I am not lying and that my eyes are functioning appropriately. This is what I meant about implicit assumptions about our base claim. I do not need to reasonably prove to you that I did in fact see a frog. **I saw a frog** is an implicitly accepted claim. Therefore, based on our rules, **all frogs are green** should be true. Obviously, something is wrong. We know that not every frog is green. How did an unaccepted claim come from an accepted one?
> * * *
> Assuming the reasoning is valid, a claim is only as true as the base claim it is reasoned from.
> * * *

Our reasoning must be invalid.

This can be further explained by another rule we made:

> * * *
> The more **similar** a claim is to a base claim the **more valid** the reasoning between them tends to be.
>
> The more **different** a claim is from a base claim the **less valid** the reasoning between them tends to be.
> * * *

Notice that our base claim only refers to a single, specific frog (the one that I saw) and that our non-base claim refers to literally every frog in existence. That's quite a big difference. Therefore, using the reason **It is green** is not enough of a valid reason to claim that **all frogs are green.** That is why this is a bad argument: the base claim and non-base claim are too far apart for the reasoning to relate the two.

Theoretically, we could fix our argument by saying,

**I saw a frog. It is green. The frog that I saw is green.** 
 
This is obviously true, but it is not meaningful to us. It is the same as saying _1 = 1_.

How about: **I saw a frog. It is green. That species of frog is green.**

This is better, and it says something meaningful. It is no longer _1 = 1_. Instead we can describe this as _1 = 1 + dx_; this statement is not true. But, if _dx_ is a very small number (close to zero) then we can accept that our statement is reasonably true. _1 = 1.001_ is probably acceptable to us (in the real world what kind of tolerance/error is acceptable is dependent on lots of outside factors and specifics, the math for us is just supposed to be illustrative since we are working in a heavily qualitative space anyways).

I would claim, and I think most people would agree, that the "_dx_" for our argument is still too large. We are comparing an entire species to one frog. A better argument would be:

**I saw a frog. It is green. That species of frog can be green.**

This is much better. Now we are not comparing a single frog to an _entire species_ of frog but a single frog to _possible frogs_ within a species. I think most people would be willing to accept this claim based on the fact that you saw a green frog of that species. 

But what if we _are_ trying to claim that **all frogs are green**? The process we went through is no longer helpful because we can no longer change our claim to bring it closer to the base claim. This is purpose of the unit argument. Unit arguments can be used to build unit argument chains (for brevity I will occasionally refer to these as unit chains with the word argument implied). There are two types of unit argument chains:

> A **horizontal unit argument chain** is a collection of some number of unit arguments where the claim of the 1st unit argument is the base claim of the 2nd unit argument and the claim of the 2nd unit argument is the base claim of the 3rd unit argument and so on and so forth.
>
> A **vertical unit argument chain** is a collection of some number of unit arguments where the claim of all unit arguments are used as the base claim for a single unit argument.

Based on our unit argument chain structure we will define an argument as:

> An **argument (or non-unit argument)** is the first base claim of a unit argument chain (or all base claims for a vertical unit argument chain) and the last non-base claim of a unit argument chain.


Similar to this rule:
> * * *
> The more **similar** a claim is to a base claim the **more valid** the reasoning between them tends to be.
>
> The more **different** a claim is from a base claim the **less valid** the reasoning between them tends to be.
> * * *

our arguments and unit chains have the rule:

> The **more unit arguments** in a unit argument chain the **more likely** an argument's claim is as true as it's base claim.
>
> The **less unit arguments** in a unit argument chain the **less likely** an argument's claim is as true as it's base claim.

Basically, we want to keep our leaps in logic as short as possible. Going back to our _1 = 1 + dx_ analogy. But let's you want to prove _1 = 2_. You could make a unit chain like this:

_1 = 1.1 = 1.2 = 1.3 = 1.4 = 1.5 = 1.6 = 1.7 = 1.8 = 1.9 = 2 => 1 = 2_

But while _1 = 1.1_ might be acceptable and _1.1 = 1.2_ and so on we know that _1 = 2_ is not acceptable. Therefore we will say:

> An argument's claim is only as true as the sum truth of its unit chain. 

In this case we might say that _1 = 1.1_ is only a little false. We might say this for each of the unit arguments. 

-0.1 + -0.1 + -0.1 + -0.1 + -0.1 + -0.1 + -0.1 + -0.1 + -0.1 + -0.1 = -1

Based on our scale* before where,
> * * *
> * True = 1
> * Uncertain = 0
> * False = -1
>
> *Technically you can end up with something more false than false (>1) so to bring it in range you would need to scale by the difference in truth between the non-base claim and base claim. This is more so a thing for our mathematical illustration.
> * * *

we can see that from too many claims that are slightly false we have reached a completely false claim. This creates a balancing game for our arguments. We want more unit arguments to bridge that gap between our starting the non-base claim and base claim of our argument, but if each unit argument is not totally true then our argument will start to weaken the more we add. This can be helped by incorporating accepted claims into our unit chain.




